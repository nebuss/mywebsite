import numpy as np
import pandas as pd
import statsmodels.api as sm

data=  pd.read_table('C:/Users/USER/Documents/LSë¹…ë°ì´í„°ìŠ¤ì¿¨/LSbigdata-project1/data/leukemia_remission.txt', delimiter='\t')
print(data.head())  # ë°ì´í„° í™•ì¸

#ì¢…ì†ë³€ìˆ˜: ë°±í˜ˆë³‘ ì„¸í¬ ê´€ì¸¡ ë¶ˆê°€ ì—¬ë¶€ (REMISS), 1ì´ë©´ ê´€ì¸¡ ì•ˆë¨ì„ ì˜ë¯¸
# ë…ë¦½ë³€ìˆ˜:
# ê³¨ìˆ˜ì˜ ì„¸í¬ì„± (CELL)
# ê³¨ìˆ˜í¸ì˜ ë°±í˜ˆêµ¬ ë¹„ìœ¨ (SMEAR)
# ê³¨ìˆ˜ì˜ ë°±í˜ˆë³‘ ì„¸í¬ ì¹¨íˆ¬ ë¹„ìœ¨ (INFIL)
# ê³¨ìˆ˜ ë°±í˜ˆë³‘ ì„¸í¬ì˜ ë¼ë²¨ë§ ì¸ë±ìŠ¤ (LI)
# ë§ì´ˆí˜ˆì•¡ì˜ ë°±í˜ˆë³‘ ì„¸í¬ ìˆ˜ (BLAST)
# ì¹˜ë£Œ ì‹œì‘ ì „ ìµœê³  ì²´ì˜¨ (TEMP)


# ë¬¸ì œ1. ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨ë¸ì„ ì í•©í•˜ê³ , íšŒê·€ í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
X = data[['CELL', 'SMEAR', 'INFIL', 'LI', 'BLAST', 'TEMP']]  # Independent variables
y = data['REMISS'] 

X = sm.add_constant(X)

logit_model = sm.Logit(y, X)
result = logit_model.fit()

logit_summary = result.summary()
logit_summary

# ë¬¸ì œ2. í•´ë‹¹ ëª¨ë¸ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œê°€ìš”? ê·¸ ì´ìœ ë¥¼ ê²€ì •í†µê³„ëŸ‰ë¥¼ ì‚¬ìš©í•´ì„œ ì„¤ëª…í•˜ì‹œì˜¤.

llr_pvalue = result.llr_pvalue #ìš°ë„ë¹„ ê²€ì •ì˜ p-value : 0.04670
ll_null = result.llnull  #  ë…ë¦½ ë³€ìˆ˜ ì—†ì´ ìƒìˆ˜í•­(intercept)ë§Œì„ í¬í•¨í•œ ê·€ë¬´ëª¨í˜•ì˜ ë¡œê·¸ ìš°ë„ë°˜í™˜: -17.1858
ll_model = result.llf  # ë…ë¦½ ë³€ìˆ˜ë¥¼ í¬í•¨í•œ ëª¨ë¸ë¡œ, ë…ë¦½ ë³€ìˆ˜ë“¤ì´ ì¢…ì† ë³€ìˆ˜ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤ê³  ê°€ì •: (-10.79692
lr_stat = 2 * (ll_model - ll_null) # LR statistic: 12.7779  í´ìˆ˜ë¡ ë…ë¦½ ë³€ìˆ˜ë¥¼ ì¶”ê°€í•œ ëª¨ë¸ì´ ì¢…ì† ë³€ìˆ˜ë¥¼ ë” ì˜ ì„¤ëª…í•œë‹¤

llr_pvalue, lr_stat #  p-valueê°€ 0.05ë³´ë‹¤ ì‘ìœ¼ë¯€ë¡œ, 95% ì‹ ë¢°ìˆ˜ì¤€ì—ì„œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°
from scipy.stats import chi2
# âˆ’2(â„“(ğ›½)Ì‚ (0) âˆ’ â„“(ğ›½)Ì‚ )  =  -2*(-17.186+10.797)  = 12.779
1 - chi2.cdf(12.779, df=6)  # 0.0467



# ë¬¸ì œ3. ìœ ì˜ìˆ˜ì¤€ì´ 0.2ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ë³€ìˆ˜ëŠ” ëª‡ê°œì´ë©°, ì–´ëŠ ë³€ìˆ˜ ì¸ê°€ìš”?
p_values = result.pvalues
p_values[p_values < 0.2]
# 2ê°œ.  LI ,  TEMP

# ë¬¸ì œ4. ë‹¤ìŒ í™˜ìì— ëŒ€í•œ ì˜¤ì¦ˆëŠ” ì–¼ë§ˆì¸ê°€ìš”?


# CELL (ê³¨ìˆ˜ì˜ ì„¸í¬ì„±): 65%
# SMEAR (ê³¨ìˆ˜í¸ì˜ ë°±í˜ˆêµ¬ ë¹„ìœ¨): 45%
# INFIL (ê³¨ìˆ˜ì˜ ë°±í˜ˆë³‘ ì„¸í¬ ì¹¨íˆ¬ ë¹„ìœ¨): 55%
# LI (ê³¨ìˆ˜ ë°±í˜ˆë³‘ ì„¸í¬ì˜ ë¼ë²¨ë§ ì¸ë±ìŠ¤): 1.2
# BLAST (ë§ì´ˆí˜ˆì•¡ì˜ ë°±í˜ˆë³‘ ì„¸í¬ ìˆ˜): 1.1ì„¸í¬/Î¼L
# TEMP (ì¹˜ë£Œ ì‹œì‘ ì „ ìµœê³  ì²´ì˜¨): 0.9
coefficients = result.params
patient_data = {
    'const': 1,  # Intercept
    'CELL': 0.65,  # 65%
    'SMEAR': 0.45,  # 45%
    'INFIL': 0.55,  # 55%
    'LI': 1.2,  # LI value
    'BLAST': 1.1,  # BLAST value in cells/Î¼L
    'TEMP': 0.9  # TEMP value (already scaled)
}

log_odds = sum(coefficients[var] * patient_data[var] for var in patient_data)

odds = np.exp(log_odds)

log_odds, odds # -3.2656, 0.03817

# ë¬¸ì œ 5. ìœ„ í™˜ìì˜ í˜ˆì•¡ì—ì„œ ë°±í˜ˆë³‘ ì„¸í¬ê°€ ê´€ì¸¡ë˜ì§€ ì•Šì€ í™•ë¥ ì€ ì–¼ë§ˆì¸ê°€ìš”?
prob = 1 / (1 + np.exp(-log_odds))
prob # 0.036767

# ë¬¸ì œ 6. TEMP ë³€ìˆ˜ì˜ ê³„ìˆ˜ëŠ” ì–¼ë§ˆì´ë©°, í•´ë‹¹ ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ TEMP ë³€ìˆ˜ê°€ ë°±í˜ˆë³‘ ì¹˜ë£Œì— ëŒ€í•œ ì˜í–¥ì„ ì„¤ëª…í•˜ì‹œì˜¤.

temp_coef = coefficients['TEMP'] # -100.17340

temp_odds_ratio = np.exp(temp_coef)
temp_odds_ratio  # 3.13e-44 - > 0ì— ê°€ê¹Œìš´ ê°’ì…ë‹ˆë‹¤. ì´ëŠ” ì²´ì˜¨ì´ 1ë‹¨ìœ„ ìƒìŠ¹í•  ë•Œ ë°±í˜ˆë³‘ ì„¸í¬ê°€ ê´€ì¸¡ë˜ì§€ ì•Šì„ í™•ë¥ ì´ (ì˜¤ì¦ˆë¹„ë§Œí¼ ë³€ë™)ê±°ì˜ ì—†ì–´ì§€ëŠ” ê²ƒì„ ì˜ë¯¸ ->  ì˜¨ë„ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ë°±í˜ˆë³‘ ì„¸í¬ê°€ ê´€ì¸¡ë  í™•ë¥  ë†’ì•„ì§.

# ë¬¸ì œ 7. CELL ë³€ìˆ˜ì˜ 99% ì˜¤ì¦ˆë¹„ì— ëŒ€í•œ ì‹ ë¢°êµ¬ê°„ì„ êµ¬í•˜ì‹œì˜¤.
cell_coef = coefficients['CELL']
cell_se = result.bse['CELL']  # bseëŠ” **í‘œì¤€ ì˜¤ì°¨(Standard Errors, SE)ê°€ ì €ì¥ëœ ì†ì„±

z_value = 2.576 # 99% ì‹ ë¢°êµ¬ê°„ì—ì„œ zê°’

lower_log_odds = cell_coef - z_value * cell_se
upper_log_odds = cell_coef + z_value * cell_se

lower_odds_ratio = np.exp(lower_log_odds)
upper_odds_ratio = np.exp(upper_log_odds)

lower_odds_ratio, upper_odds_ratio # 0ì— ê°€ê¹Œìš´ìˆ˜, ì—„ì²­ í° ìˆ˜.

# ë¬¸ì œ 8. ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ êµ¬í•œ í›„, 50% ì´ìƒì¸ ê²½ìš° 1ë¡œ ì²˜ë¦¬í•˜ì—¬, í˜¼ë™ í–‰ë ¬ë¥¼ êµ¬í•˜ì‹œì˜¤.
from sklearn.metrics import confusion_matrix
predicted_probabilities = result.predict(X)
predicted_classes = (predicted_probabilities >= 0.5).astype(int)
conf_matrix = confusion_matrix(y, predicted_classes)
conf_matrix  

# ì‹œê°í™”
import matplotlib.pyplot as plt
import seaborn as sns

# í˜¼ë™í–‰ë ¬ ë°ì´í„°
conf_matrix = [[15, 3], [4, 5]]

# í˜¼ë™í–‰ë ¬ ì‹œê°í™”
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

# ë¬¸ì œ 9. í•´ë‹¹ ëª¨ë¸ì˜ AccuracyëŠ” ì–¼ë§ˆì¸ê°€ìš”?


accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / conf_matrix.sum()
accuracy # ì •í™•ë„: ì•½ 74.07%

# ë¬¸ì œ 10. í•´ë‹¹ ëª¨ë¸ì˜ F1 Scoreë¥¼ êµ¬í•˜ì„¸ìš”.
from sklearn.metrics import f1_score

f1 = f1_score(y, predicted_classes)
f1  # 0.58823